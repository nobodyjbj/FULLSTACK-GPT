{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\" # 모델 이름\n",
    "    #, api_key=key # API 키\n",
    "    , temperature=0.1 # 창의력\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국과 일본 사이의 거리는 약 800km입니다. 저의 이름은 쳇! 입니다. 어떻게 도와드릴까요?')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Korean.\"),\n",
    "    AIMessage(content=\"안녕하세요. 제 이름은 쳇! 입니다.\"),\n",
    "    HumanMessage(content=\"What is the distance between korea and japan?, What is your name?\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Korea and Japan varies depending on the specific locations being measured. On average, the distance between Seoul, South Korea and Tokyo, Japan is approximately 1,100 kilometers (683 miles) when measured in a straight line. However, the actual distance can be longer when taking into account the specific points of departure and arrival, as well as the mode of transportation being used.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate 사용\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country1} and {country2}\")\n",
    "prompt = template.format(country1 = \"Korea\", country2 = \"japan\")\n",
    "\n",
    "prompt = template.format(\n",
    "  country1 = \"Korea\",\n",
    "  country2 = \"Japan\"\n",
    ")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국과 일본 사이의 거리는 약 800km입니다. 제 이름은 쳇! 입니다.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromptTemplate 사용\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"안녕하세요. 제 이름은 {name} 입니다.\"),\n",
    "    (\"human\", \"What is the distance between {country1} and {country2}?, Also, what is your name?\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "  language=\"Korean\"\n",
    "  , name=\"쳇!\"\n",
    "  , country1=\"Korea\"\n",
    "  , country2=\"Japan\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heelow', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OutputParser 사용\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\") # 앞 뒤 공백을 제거 후 \",\" 로 분리\n",
    "        return list(map(str.strip, items))\n",
    "      \n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Heelow, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu',\n",
       " 'Charmander',\n",
       " 'Bulbasaur',\n",
       " 'Squirtle',\n",
       " 'Jigglypuff',\n",
       " 'Eevee',\n",
       " 'Snorlax',\n",
       " 'Mewtwo',\n",
       " 'Gengar',\n",
       " 'Lucario']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain expression language 사용\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are list generatting machine. Everything you are asked \" + \n",
    "      \"will be answerd with a comma separated list of max {max_items}.\" + \n",
    "      \"Do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "  ]\n",
    ")\n",
    "\n",
    "# chain 으로 Chat, ChatPromptTemplate, OutputParser를 한 번에 작성 할 수 있다.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({\n",
    "  \"max_items\": 10,\n",
    "  \"question\": \"What are the Pocketmons?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of my favorite Indian dishes to make is Chicken Tikka Masala. It's a flavorful and creamy dish that is sure to impress your friends and family. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tbsp lemon juice\n",
      "- 2 tsp ground cumin\n",
      "- 2 tsp paprika\n",
      "- 1 tsp ground cinnamon\n",
      "- 1 tsp cayenne pepper\n",
      "- 1 tsp ground black pepper\n",
      "- 1 tsp salt\n",
      "- 1 tbsp grated fresh ginger\n",
      "- 3 cloves garlic, minced\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup heavy cream\n",
      "- 2 tbsp vegetable oil\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "Instructions:\n",
      "1. In a large bowl, combine the yogurt, lemon juice, cumin, paprika, cinnamon, cayenne pepper, black pepper, salt, ginger, and garlic. Add the chicken pieces and toss to coat. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. In a large skillet, heat the vegetable oil over medium-high heat. Add the marinated chicken pieces and cook until browned on all sides, about 5-7 minutes.\n",
      "\n",
      "3. Stir in the tomato sauce and bring to a simmer. Reduce heat to low, cover, and cook for 15-20 minutes, or until the chicken is cooked through.\n",
      "\n",
      "4. Stir in the heavy cream and simmer for an additional 5 minutes.\n",
      "\n",
      "5. Serve the Chicken Tikka Masala over cooked rice or with naan bread. Garnish with fresh cilantro.\n",
      "\n",
      "Enjoy your delicious homemade Chicken Tikka Masala!To make a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based protein such as tofu or seitan. Here's how you can modify the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb firm tofu or seitan, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (use dairy-free yogurt for a vegan option)\n",
      "- 2 tbsp lemon juice\n",
      "- 2 tsp ground cumin\n",
      "- 2 tsp paprika\n",
      "- 1 tsp ground cinnamon\n",
      "- 1 tsp cayenne pepper\n",
      "- 1 tsp ground black pepper\n",
      "- 1 tsp salt\n",
      "- 1 tbsp grated fresh ginger\n",
      "- 3 cloves garlic, minced\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup coconut cream (or dairy-free heavy cream alternative)\n",
      "- 2 tbsp vegetable oil\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "Instructions:\n",
      "1. In a large bowl, combine the yogurt, lemon juice, cumin, paprika, cinnamon, cayenne pepper, black pepper, salt, ginger, and garlic. Add the tofu or seitan pieces and toss to coat. Cover and refrigerate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. In a large skillet, heat the vegetable oil over medium-high heat. Add the marinated tofu or seitan pieces and cook until browned on all sides, about 5-7 minutes.\n",
      "\n",
      "3. Stir in the tomato sauce and bring to a simmer. Reduce heat to low, cover, and cook for 15-20 minutes, or until the tofu or seitan is heated through.\n",
      "\n",
      "4. Stir in the coconut cream and simmer for an additional 5 minutes.\n",
      "\n",
      "5. Serve the Vegetarian Tikka Masala over cooked rice or with naan bread. Garnish with fresh cilantro.\n",
      "\n",
      "Enjoy your delicious homemade Vegetarian Tikka Masala!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Chicken Tikka Masala, you can replace the chicken with a plant-based protein such as tofu or seitan. Here's how you can modify the recipe:\\n\\nIngredients:\\n- 1 lb firm tofu or seitan, cut into bite-sized pieces\\n- 1 cup plain yogurt (use dairy-free yogurt for a vegan option)\\n- 2 tbsp lemon juice\\n- 2 tsp ground cumin\\n- 2 tsp paprika\\n- 1 tsp ground cinnamon\\n- 1 tsp cayenne pepper\\n- 1 tsp ground black pepper\\n- 1 tsp salt\\n- 1 tbsp grated fresh ginger\\n- 3 cloves garlic, minced\\n- 1 can (14 oz) tomato sauce\\n- 1 cup coconut cream (or dairy-free heavy cream alternative)\\n- 2 tbsp vegetable oil\\n- Fresh cilantro, chopped (for garnish)\\n- Cooked rice or naan bread (for serving)\\n\\nInstructions:\\n1. In a large bowl, combine the yogurt, lemon juice, cumin, paprika, cinnamon, cayenne pepper, black pepper, salt, ginger, and garlic. Add the tofu or seitan pieces and toss to coat. Cover and refrigerate for at least 1 hour, or overnight for best results.\\n\\n2. In a large skillet, heat the vegetable oil over medium-high heat. Add the marinated tofu or seitan pieces and cook until browned on all sides, about 5-7 minutes.\\n\\n3. Stir in the tomato sauce and bring to a simmer. Reduce heat to low, cover, and cook for 15-20 minutes, or until the tofu or seitan is heated through.\\n\\n4. Stir in the coconut cream and simmer for an additional 5 minutes.\\n\\n5. Serve the Vegetarian Tikka Masala over cooked rice or with naan bread. Garnish with fresh cilantro.\\n\\nEnjoy your delicious homemade Vegetarian Tikka Masala!\")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"Your are world-class international chef. you create easy to follow recipies for any type of cusine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to {cuisine} food.\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\" \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\" : chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "  \"cuisine\": \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# PromptTemplate 사용 \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# 아래 주석된 코드와 동일한 코드이다.\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "\n",
    "# t = PromptTemplate(\n",
    "#   template=\"What is the capital of {country}?\",\n",
    "#   input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "t.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Seoul\n",
      "      Language: Korean\n",
      "      Food: Kimchi and Bibimbap\n",
      "      Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n      Here is what I know:\\n      Capital: Seoul\\n      Language: Korean\\n      Food: Kimchi and Bibimbap\\n      Currency: South Korean Won')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotPromptTemplate 사용, FewShot은 모델에서 예시를 준다는 뜻\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# 우리가 원하는 답의 형태\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"What do you know about France?\",\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Italy?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Greece?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "]\n",
    "\n",
    "# 형식화 하기\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "  example_prompt=example_prompt,\n",
    "  examples=examples,\n",
    "  suffix=\"Human: What do you know about {country}?\", # 마지막에 내용 포함\n",
    "  input_variables=[\"country\"], # 입력받을 값 지정\n",
    ")\n",
    "\n",
    "# few_shot_prompt.format(country=\"Korea\")\n",
    "\n",
    "chain = few_shot_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "  \"country\": \"Korea\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      I know this:\n",
      "      South Korea:\n",
      "      Capital: Seoul\n",
      "      Language: Korean\n",
      "      Food: Kimchi and Bibimbap\n",
      "      Currency: South Korean Won\n",
      "\n",
      "      North Korea:\n",
      "      Capital: Pyongyang\n",
      "      Language: Korean\n",
      "      Currency: North Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n      I know this:\\n      South Korea:\\n      Capital: Seoul\\n      Language: Korean\\n      Food: Kimchi and Bibimbap\\n      Currency: South Korean Won\\n\\n      North Korea:\\n      Capital: Pyongyang\\n      Language: Korean\\n      Currency: North Korean Won')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# 우리가 원하는 답의 형태\n",
    "examples = [\n",
    "  {\n",
    "      \"country\": \"France\",\n",
    "      \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "      \"country\": \"Italy\",\n",
    "      \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "      \"country\": \"Greece\",\n",
    "      \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]\n",
    "\n",
    "# 형식화 하기\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_prompt,\n",
    "  examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Greece?\\nAI: \\n      I know this:\\n      Capital: Athens\\n      Language: Greek\\n      Food: Souvlaki and Feta Cheese\\n      Currency: Euro\\n    \\n\\nHuman: What do you know about France?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dynamic 하게 example 을 선택 및 BaseExmapleSelector 사용 법\n",
    "from typing import Any, Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# 우리가 원하는 답의 형태\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"What do you know about France?\",\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Italy?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Greece?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "    \"\"\",\n",
    "  },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "  \n",
    "  def __init__(self, examples):\n",
    "    self.examples = examples\n",
    "    \n",
    "  def add_example(self, example):\n",
    "    self.examples.append(example)\n",
    "  \n",
    "  def select_examples(self, input_variables):\n",
    "    from random import choice\n",
    "    return [choice(self.examples)]\n",
    "\n",
    "# 형식화 하기\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "  examples=examples\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "  example_prompt=example_prompt,\n",
    "  example_selector=example_selector,\n",
    "  suffix=\"Human: What do you know about {country}?\", # 마지막에 내용 포함\n",
    "  input_variables=[\"country\"], # 입력받을 값 지정\n",
    ")\n",
    "\n",
    "prompt.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트를 import 하는 방법, json, yaml\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg matey! Me favorite grub be a hearty plate o' salted beef and hardtack! Aye, nothing beats the taste o' the sea! Arrrrg!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg matey! Me favorite grub be a hearty plate o' salted beef and hardtack! Aye, nothing beats the taste o' the sea! Arrrrg!\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트들의 memory 등을 다 모으는 방법\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  , streaming=True\n",
    "  , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cash, debug, sql\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache())\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "set_debug(False)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    "  # , streaming=True\n",
    "  # , callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beer is typically made using the following ingredients and steps:\n",
      "\n",
      "Ingredients:\n",
      "- Water\n",
      "- Barley malt\n",
      "- Hops\n",
      "- Yeast\n",
      "\n",
      "Steps:\n",
      "1. Malting: Barley grains are soaked in water and allowed to germinate. The germinated barley is then dried in a kiln to stop the germination process, creating malted barley.\n",
      "\n",
      "2. Mashing: The malted barley is crushed and mixed with hot water in a process called mashing. This helps to extract the sugars from the barley.\n",
      "\n",
      "3. Boiling: The liquid extracted from the mashing process, known as wort, is boiled and hops are added for flavor and aroma. The boiling process also helps to sterilize the wort.\n",
      "\n",
      "4. Fermentation: The boiled wort is cooled and yeast is added. The yeast consumes the sugars in the wort and produces alcohol and carbon dioxide as byproducts. This process typically takes 1-2 weeks.\n",
      "\n",
      "5. Conditioning: After fermentation is complete, the beer is conditioned for a period of time to allow flavors to develop and the beer to mature.\n",
      "\n",
      "6. Packaging: The beer is then filtered, carbonated, and packaged in bottles, cans, or kegs for distribution and consumption.\n",
      "\n",
      "Please note that there are many variations and styles of beer, each with their own unique ingredients and processes. Ingredients:\n",
      "- 3 cups all-purpose flour\n",
      "- 1 packet active dry yeast\n",
      "- 1 1/4 cups warm water\n",
      "- 1 tablespoon sugar\n",
      "- 1 teaspoon salt\n",
      "- 2 tablespoons olive oil\n",
      "\n",
      "Instructions:\n",
      "1. In a small bowl, dissolve the yeast and sugar in the warm water. Let it sit for about 10 minutes, until it becomes frothy.\n",
      "2. In a large mixing bowl, combine the flour and salt. Make a well in the center and pour in the yeast mixture and olive oil.\n",
      "3. Stir the mixture until a dough forms. Knead the dough on a floured surface for about 10 minutes, until it becomes smooth and elastic.\n",
      "4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1 hour, or until it has doubled in size.\n",
      "5. Preheat the oven to 375°F (190°C). Punch down the dough and shape it into a loaf. Place the loaf on a greased baking sheet and let it rise for another 30 minutes.\n",
      "6. Bake the bread in the preheated oven for about 30-35 minutes, or until it is golden brown and sounds hollow when tapped on the bottom.\n",
      "7. Let the bread cool before slicing and serving. Enjoy! \n",
      "\n",
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "# 비용 측정 방법, 모델 저장 및 불러오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "  a = chat.predict(\"What is the recipe for beer.\")\n",
    "  b = chat.predict(\"What is the recipe for bread.\")\n",
    "  print(a, b, \"\\n\")\n",
    "  print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
